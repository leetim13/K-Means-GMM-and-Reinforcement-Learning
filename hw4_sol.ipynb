{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import scipy\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating the data\n",
    "\n",
    "First, we will generate some data for this problem. Set the number of points $N=400$, their dimension $D=2$, and the number of clusters $K=2$, and generate data from the distribution $p(x|z=k) = \\mathcal{N}(\\mu_k, \\Sigma_k)$.\n",
    "  Sample $200$ data points for $k=1$ and 200 for $k=2$, with\n",
    "\n",
    "  $$\n",
    "    \\mu_1=\n",
    "    \\begin{bmatrix}\n",
    "      0.1 \\\\\n",
    "      0.1\n",
    "    \\end{bmatrix}\n",
    "    \\ \\text{,}\\\n",
    "    \\mu_2=\n",
    "    \\begin{bmatrix}\n",
    "      6.0 \\\\\n",
    "      0.1\n",
    "    \\end{bmatrix}\n",
    "    \\ \\text{ and }\\\n",
    "    \\Sigma_1=\\Sigma_2=\n",
    "    \\begin{bmatrix}\n",
    "      10       & 7 \\\\\n",
    "      7 & 10\n",
    "    \\end{bmatrix}\n",
    "  $$\n",
    "  Here, $N=400$. Since you generated the data, you already know which sample comes from which class.\n",
    "  Run the cell in the IPython notebook to generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this cell to generate the data\n",
    "num_samples = 400\n",
    "cov = np.array([[1., .7], [.7, 1.]]) * 10\n",
    "mean_1 = [.1, .1]\n",
    "mean_2 = [6., .1]\n",
    "\n",
    "x_class1 = np.random.multivariate_normal(mean_1, cov, num_samples // 2)\n",
    "x_class2 = np.random.multivariate_normal(mean_2, cov, num_samples // 2)\n",
    "xy_class1 = np.column_stack((x_class1, np.zeros(num_samples // 2)))\n",
    "xy_class2 = np.column_stack((x_class2, np.ones(num_samples // 2)))\n",
    "data_full = np.row_stack([xy_class1, xy_class2])\n",
    "np.random.shuffle(data_full)\n",
    "data = data_full[:, :2]\n",
    "labels = data_full[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatter plot of the data points showing the true cluster assignment of each point using different color codes and shape (x for first class and circles for second class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a scatterplot for the data points showing the true cluster assignments of each point\n",
    "# plt.plot(...) # first class, x shape\n",
    "# plt.plot(...) # second class, circle shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement and Run K-Means algorithm\n",
    "\n",
    "Now, we assume that the true class labels are not known. Implement the k-means algorithm for this problem.\n",
    "  Write two functions: `km_assignment_step`, and `km_refitting_step` as given in the lecture (Here, `km_` means k-means).\n",
    "  Identify the correct arguments, and the order to run them. Initialize the algorithm with\n",
    "  $$\n",
    "    \\hat\\mu_1=\n",
    "    \\begin{bmatrix}\n",
    "      0.0 \\\\\n",
    "      0.0\n",
    "    \\end{bmatrix}\n",
    "    \\ \\text{,}\\\n",
    "    \\hat\\mu_2=\n",
    "    \\begin{bmatrix}\n",
    "      1.0 \\\\\n",
    "      1.0\n",
    "    \\end{bmatrix}\n",
    "  $$\n",
    "  and run it until convergence.\n",
    "  Show the resulting cluster assignments on a scatter plot either using different color codes or shape or both.\n",
    "  Also plot the cost vs. the number of iterations. Report your misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(data, R, Mu):\n",
    "    N, D = data.shape\n",
    "    K = Mu.shape[1]\n",
    "    J = 0\n",
    "    for k in range(K):\n",
    "        J += np.dot(np.linalg.norm(data - np.array([Mu[:, k], ] * N), axis=1)**2, R[:, k])\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: K-Means Assignment Step\n",
    "def km_assignment_step(data, Mu):\n",
    "    \"\"\" Compute K-Means assignment step\n",
    "    \n",
    "    Args:\n",
    "        data: a NxD matrix for the data points\n",
    "        Mu: a DxK matrix for the cluster means locations\n",
    "    \n",
    "    Returns:\n",
    "        R_new: a NxK matrix of responsibilities\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fill this in:\n",
    "    # N, D = ... # Number of datapoints and dimension of datapoint\n",
    "    # K = ... # number of clusters\n",
    "    # r = ...\n",
    "    for k in range(K):\n",
    "        # r[:, k] = ...\n",
    "    # arg_min = ... # argmax/argmin along dimension 1\n",
    "    # R_new = ... # Set to zeros/ones with shape (N, K)\n",
    "    # R_new[..., ...] = 1 # Assign to 1\n",
    "    return R_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: K-means Refitting Step\n",
    "def km_refitting_step(data, R, Mu):\n",
    "    \"\"\" Compute K-Means refitting step.\n",
    "    \n",
    "    Args:\n",
    "        data: a NxD matrix for the data points\n",
    "        R: a NxK matrix of responsibilities\n",
    "        Mu: a DxK matrix for the cluster means locations\n",
    "    \n",
    "    Returns:\n",
    "        Mu_new: a DxK matrix for the new cluster means locations\n",
    "    \"\"\"\n",
    "    # N, D = ... # Number of datapoints and dimension of datapoint\n",
    "    # K = ...  # number of clusters\n",
    "    # Mu_new = ...\n",
    "    return Mu_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this cell to call the K-means algorithm\n",
    "N, D = data.shape\n",
    "K = 2\n",
    "max_iter = 100\n",
    "class_init = np.random.binomial(1., .5, size=N)\n",
    "R = np.vstack([class_init, 1 - class_init]).T\n",
    "\n",
    "Mu = np.zeros([D, K])\n",
    "Mu[:, 1] = 1.\n",
    "R.T.dot(data), np.sum(R, axis=0)\n",
    "\n",
    "for it in range(max_iter):\n",
    "    R = km_assignment_step(data, Mu)\n",
    "    Mu = km_refitting_step(data, R, Mu)\n",
    "    print(it, cost(data, R, Mu))\n",
    "\n",
    "class_1 = np.where(R[:, 0])\n",
    "class_2 = np.where(R[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a scatterplot for the data points showing the K-Means cluster assignments of each point\n",
    "# plt.plot(...) # first class, x shape\n",
    "# plt.plot(...) # second class, circle shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement EM algorithm for Gaussian mixtures\n",
    "Next, implement the EM algorithm for Gaussian mixtures.\n",
    "  Write three functions: `log_likelihood`, `gm_e_step`, and `gm_m_step` as given in the lecture.\n",
    "  Identify the correct arguments, and the order to run them.\n",
    "  Initialize the algorithm with means as in Qs 2.1 k-means initialization, covariances with $\\hat\\Sigma_1=\\hat\\Sigma_2=I$,\n",
    "  and $\\hat\\pi_1=\\hat\\pi_2$.\n",
    "\n",
    "  In addition to the update equations in the lecture, for the M (Maximization) step, you also need to use this following equation to update the covariance $\\Sigma_k$:\n",
    "$$\\hat{\\mathbf{\\Sigma}_k} = \\frac{1}{N_k} \\sum^N_{n=1} r_k^{(n)}(\\mathbf{x}^{(n)} - \\hat{\\mathbf{\\mu}_k})(\\mathbf{x}^{(n)} - \\hat{\\mathbf{\\mu}_k})^{\\top}$$\n",
    "    \n",
    "  Run the algorithm until convergence and show the resulting cluster assignments on a scatter plot either using different color codes or shape or both.\n",
    "  Also plot the log-likelihood vs. the number of iterations. Report your misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_density(x, mu, Sigma):\n",
    "    return np.exp(-.5 * np.dot(x - mu, np.linalg.solve(Sigma, x - mu))) \\\n",
    "        / np.sqrt(np.linalg.det(2 * np.pi * Sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(data, Mu, Sigma, Pi):\n",
    "    \"\"\" Compute log likelihood on the data given the Gaussian Mixture Parameters.\n",
    "    \n",
    "    Args:\n",
    "        data: a NxD matrix for the data points\n",
    "        Mu: a DxK matrix for the means of the K Gaussian Mixtures\n",
    "        Sigma: a list of size K with each element being DxD covariance matrix\n",
    "        Pi: a vector of size K for the mixing coefficients\n",
    "    \n",
    "    Returns:\n",
    "        L: a scalar denoting the log likelihood of the data given the Gaussian Mixture\n",
    "    \"\"\"\n",
    "    # Fill this in:\n",
    "    # N, D = ...  # Number of datapoints and dimension of datapoint\n",
    "    # K = ... # number of mixtures\n",
    "    L, T = 0., 0.\n",
    "    for n in range(N):\n",
    "        \n",
    "        for k in range(K):\n",
    "            # T += ... # Compute the likelihood from the k-th Gaussian weighted by the mixing coefficients \n",
    "        L += np.log(T)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gaussian Mixture Expectation Step\n",
    "def gm_e_step(data, Mu, Sigma, Pi):\n",
    "    \"\"\" Gaussian Mixture Expectation Step.\n",
    "\n",
    "    Args:\n",
    "        data: a NxD matrix for the data points\n",
    "        Mu: a DxK matrix for the means of the K Gaussian Mixtures\n",
    "        Sigma: a list of size K with each element being DxD covariance matrix\n",
    "        Pi: a vector of size K for the mixing coefficients\n",
    "    \n",
    "    Returns:\n",
    "        Gamma: a NxK matrix of responsibilities \n",
    "    \"\"\"\n",
    "    # Fill this in:\n",
    "    # N, D = ... # Number of datapoints and dimension of datapoint\n",
    "    # K = ... # number of mixtures\n",
    "    # Gamma = ... # zeros of shape (N,K), matrix of responsibilities\n",
    "    for n in range(N):\n",
    "        for k in range(K):\n",
    "            # Gamma[n, k] = .... \n",
    "        # Gamma[n, :] /= ... # Normalize by sum across second dimension (mixtures)\n",
    "    return Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gaussian Mixture Maximization Step\n",
    "def gm_m_step(data, Gamma):\n",
    "    \"\"\" Gaussian Mixture Maximization Step.\n",
    "\n",
    "    Args:\n",
    "        data: a NxD matrix for the data points\n",
    "        Gamma: a NxK matrix of responsibilities \n",
    "    \n",
    "    Returns:\n",
    "        Mu: a DxK matrix for the means of the K Gaussian Mixtures\n",
    "        Sigma: a list of size K with each element being DxD covariance matrix\n",
    "        Pi: a vector of size K for the mixing coefficients\n",
    "    \"\"\"\n",
    "    # Fill this in:\n",
    "    # N, D = ... # Number of datapoints and dimension of datapoint\n",
    "    # K = ...  # number of mixtures\n",
    "    # Nk = ... # Sum along first axis \n",
    "    # Mu = ... \n",
    "    # Sigma = ...\n",
    "\n",
    "    for k in range(K):\n",
    "        # ...\n",
    "        # Sigma[k] = ... \n",
    "    # Pi = ... \n",
    "    return Mu, Sigma, Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run this cell to call the Gaussian Mixture EM algorithm\n",
    "N, D = data.shape\n",
    "K = 2\n",
    "Mu = np.zeros([D, K])\n",
    "Mu[:, 1] = 1.\n",
    "Sigma = [np.eye(2), np.eye(2)]\n",
    "Pi = np.ones(K) / K\n",
    "Gamma = np.zeros([N, K]) # Gamma is the matrix of responsibilities \n",
    "\n",
    "max_iter  = 200\n",
    "\n",
    "for it in range(max_iter):\n",
    "    Gamma = gm_e_step(data, Mu, Sigma, Pi)\n",
    "    Mu, Sigma, Pi = gm_m_step(data, Gamma)\n",
    "    # print(it, log_likelihood(data, Mu, Sigma, Pi)) # This function makes the computation longer, but good for debugging\n",
    "\n",
    "class_1 = np.where(Gamma[:, 0] >= .5)\n",
    "class_2 = np.where(Gamma[:, 1] >= .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a scatterplot for the data points showing the Gaussian Mixture cluster assignments of each point\n",
    "# plt.plot(...) # first class, x shape\n",
    "# plt.plot(...) # second class, circle shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comment on findings + additional experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the results:\n",
    "\n",
    "* Compare the performance of k-Means and EM based on the resulting cluster assignments.\n",
    "* Compare the performance of k-Means and EM based on their convergence rate. What is the bottleneck for which method?\n",
    "* Experiment with 5 different data realizations (generate new data), run your algorithms, and summarize your findings. Does the algorithm performance depend on different realizations of data?\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Your written answer here**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reinforcement Learning\n",
    "\n",
    "There are 3 files:\n",
    "1. `maze.py`: defines the `MazeEnv` class, the simulation environment which the Q-learning agent will interact in.\n",
    "2. `qlearning.py`: defines the `qlearn` function which you will implement, along with several helper functions. Follow the instructions in the file. \n",
    "3. `plotting_utils.py`: defines several plotting and visualization utilities. In particular, you will use `plot_steps_vs_iters`, `plot_several_steps_vs_iters`, `plot_policy_from_q`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlearning import qlearn\n",
    "from maze import MazeEnv, ProbabilisticMazeEnv\n",
    "from plotting_utils import plot_steps_vs_iters, plot_several_steps_vs_iters, plot_policy_from_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Q Learning experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Run your algorithm several times on the given environment. Use the following hyperparameters:\n",
    "1. Number of episodes = 200\n",
    "2. Alpha ($\\alpha$) learning rate = 1.0\n",
    "2. Maximum number of steps per episode = 100. An episode ends when the agent reaches a goal state, or uses the maximum number of steps per episode\n",
    "3. Gamma ($\\gamma$) discount factor = 0.9\n",
    "4. Epsilon ($\\epsilon$) for $\\epsilon$-greedy = 0.1 (10% of the time). Note that we should \"break-ties\" when the Q-values are zero for all the actions (happens initially) by essentially choosing uniformly from the action. So now you have two conditions to act randomly: for epsilon amount of the time, or if the Q values are all zero. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill this in\n",
    "# num_iters = ...\n",
    "# alpha = ...\n",
    "# gamma = ...\n",
    "# epsilon = ...\n",
    "# max_steps = ...\n",
    "# use_softmax_policy = ...\n",
    "\n",
    "# TODO: Instantiate the MazeEnv environment with default arguments\n",
    "# env = ...\n",
    "\n",
    "# TODO: Run Q-learning:\n",
    "# q_hat, steps_vs_iters = qlearn(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the steps to goal vs training iterations (episodes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the steps vs iterations\n",
    "# plot_steps_vs_iters(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the learned greedy policy from the Q values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: plot the policy from the Q value\n",
    "# plot_policy_from_q(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Run your algorithm by passing in a list of 2 goal locations: (1,8) and (5,6). Note: we are using 0-indexing, where (0,0) is top left corner. Report on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill this in (same as before)\n",
    "# num_iters = ...\n",
    "# alpha = ...\n",
    "# gamma = ...\n",
    "# epsilon = ...\n",
    "# max_steps = ...\n",
    "# use_softmax_policy = ...\n",
    "\n",
    "# TODO: Set the goal\n",
    "# goal_locs = ...\n",
    "# env = ...\n",
    "\n",
    "# TODO: Run Q-learning:\n",
    "# q_hat, steps_vs_iters = qlearn(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the steps to goal vs training iterations (episodes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the steps vs iterations\n",
    "# plot_steps_vs_iters(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the steps to goal vs training iterations (episodes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the policy from the Q values\n",
    "# plot_policy_from_q(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment with the exploration strategy, in the original environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Try different $\\epsilon$ values in $\\epsilon$-greedy exploration: We asked you to use a rate of $\\epsilon$=10%, but try also 50% and 1%. Graph the results (for 3 epsilon values) and discuss the costs and benefits of higher and lower exploration rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill this in (same as before)\n",
    "# num_iters = ...\n",
    "# alpha = ...\n",
    "# gamma = ...\n",
    "# max_steps = ...\n",
    "# use_softmax_policy = ...\n",
    "\n",
    "# TODO: set the epsilon lists in increasing order:\n",
    "# epsilon_list = ...\n",
    "\n",
    "# env = ...\n",
    "\n",
    "steps_vs_iters_list = []\n",
    "for epsilon in epsilon_list:\n",
    "#    q_hat, steps_vs_iters = qlearn(...)\n",
    "   steps_vs_iters_list.append(steps_vs_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the results\n",
    "label_list = [\"epsilon={}\".format(eps) for eps in epsilon_list]\n",
    "# plot_several_steps_vs_iters(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Try exploring with policy derived from **softmax of Q-values** described in the Q learning lecture. Use the values of $\\beta \\in \\{1, 3, 6\\}$ for your experiment, keeping $\\beta$ fixed throughout the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill this in for Static Beta with softmax of Q-values\n",
    "# num_iters = ...\n",
    "# alpha = ...\n",
    "# gamma = ...\n",
    "# epsilon = ...\n",
    "# max_steps = ...\n",
    "\n",
    "# TODO: Set the beta\n",
    "# beta_list = ...\n",
    "# use_softmax_policy = ...\n",
    "# k_exp_schedule = ... # (float) choose k such that we have a constant beta during training\n",
    "\n",
    "# env = ...\n",
    "steps_vs_iters_list = []\n",
    "for beta in beta_list:\n",
    "#     q_hat, steps_vs_iters = qlearn(...)\n",
    "    steps_vs_iters_list.append(steps_vs_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"beta={}\".format(beta) for beta in beta_list]\n",
    "# TODO: \n",
    "# plot_several_steps_vs_iters(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Instead of fixing the $\\beta = \\beta_0$ to the initial value, we will increase the value of $\\beta$ as the number of episodes $t$ increase:\n",
    "\n",
    "$$\\beta(t) = \\beta_0 e^{kt}$$\n",
    "\n",
    "That is, the $\\beta$ value is fixed for a particular episode.\n",
    "Run the training again for different values of $k \\in \\{0.05, 0.1, 0.25, 0.5\\}$, keeping $\\beta_0 = 1.0$. Compare the results obtained with this approach to those obtained with a static $\\beta$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill this in for Dynamic Beta\n",
    "# num_iters = ...\n",
    "# alpha = ...\n",
    "# gamma = ...\n",
    "# epsilon = ...\n",
    "# max_steps = ...\n",
    "\n",
    "# TODO: Set the beta\n",
    "beta = 1.0\n",
    "# use_softmax_policy = ...\n",
    "# k_exp_schedule_list = ...\n",
    "# env = ...\n",
    "\n",
    "steps_vs_iters_list = []\n",
    "for k_exp_schedule in k_exp_schedule_list:\n",
    "#     q_hat, steps_vs_iters = qlearn(...)\n",
    "    steps_vs_iters_list.append(steps_vs_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot the steps vs iterations\n",
    "label_list = [\"k={}\".format(k_exp_schedule) for k_exp_schedule in k_exp_schedule_list]\n",
    "# plot_several_steps_vs_iters(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stochastic Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Make  the  environment  stochastic  (uncertain),  such  that  the  agent  only  has  a  95% chance  of  moving  in  the  chosen  direction,  and  has  a  5%  chance  of  moving  in  some random direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement ProbabilisticMazeEnv in maze.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Change the learning rule to handle the non-determinism, and experiment with different probability of environment performing random action $p_{rand} \\in \\{0.05, 0.1, 0.25, 0.5\\}$ in this new rule. How does performance vary as the environment becomes more stochastic?\n",
    "\n",
    "Use the same parameters as in first part, except change the alpha ($\\alpha$) value to be **less than 1**, e.g. 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use the same parameters as in the first part, except change alpha\n",
    "# num_iters = ...\n",
    "# alpha = ...\n",
    "# gamma = ...\n",
    "# epsilon = ...\n",
    "# max_steps = ...\n",
    "# use_softmax_policy = ...\n",
    "\n",
    "# Set the environment probability of random\n",
    "# env_p_rand_list = ...\n",
    "\n",
    "steps_vs_iters_list = []\n",
    "for env_p_rand in env_p_rand_list:\n",
    "    # Instantiate with ProbabilisticMazeEnv\n",
    "    # env = ...\n",
    "\n",
    "    # Note: We will repeat for several runs of the algorithm to make the result less noisy\n",
    "    avg_steps_vs_iters = np.zeros(num_iters)\n",
    "    for i in range(10):\n",
    "        # q_hat, steps_vs_iters = qlearn(...)\n",
    "        avg_steps_vs_iters += steps_vs_iters\n",
    "    avg_steps_vs_iters /= 10\n",
    "    steps_vs_iters_list.append(avg_steps_vs_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"env_random={}\".format(env_p_rand) for env_p_rand in env_p_rand_list]\n",
    "# plot_several_steps_vs_iters(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Did you complete the course evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: yes / no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
